{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sZsGGCxd0gpN"
      },
      "source": [
        "# 澳門日報爬蟲\n",
        "\n",
        " \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mbrLfat3VxxF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UkXmuyVXSzT"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import datetime\n",
        "from lxml import etree\n",
        "import pandas as pd \n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 一年中所有的日期\n",
        "def get_date_list(start,end):\n",
        "    start_year, start_month, start_day=start.split(\"/\")\n",
        "    end_year, end_month, end_day= end.split(\"/\")\n",
        "    begin = datetime.date(int(start_year), int(start_month), int(start_day))\n",
        "    end = datetime.date(int(end_year), int(end_month), int(end_day))\n",
        "    delta = datetime.timedelta(days=1)\n",
        "    days = []\n",
        "    while begin <= end:\n",
        "        days.append(begin.strftime(\"%Y-%m-%d\"))\n",
        "        begin += delta\n",
        "    date_list=list(map(lambda x: x.replace(\"-\",\"/\" ).replace(\"/\",\"-\",1), days))\n",
        "    return date_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_content(date,node_name,title,link):\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'}\n",
        "    resp = requests.get(url=link, headers=headers)\n",
        "    resp.encoding = 'utf-8'\n",
        "    html = etree.HTML(resp.text)\n",
        "    try:\n",
        "        content='\\n'.join(html.xpath('//div[@id=\"ozoom\"]//p//text()'))\n",
        "    except AttributeError:\n",
        "        content=''       \n",
        "    return [date,node_name,title,link,content]\n",
        "\n",
        "def news(start, end):\n",
        "    date_list=get_date_list(start, end)\n",
        "    #print(date_list[0:5])\n",
        "    result=[]\n",
        "    for date in date_list:\n",
        "        url=f'http://www.macaodaily.com/html/{date}/node_1.htm'\n",
        "        headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'}\n",
        "        resp=requests.get(url=url,headers=headers)\n",
        "        resp.encoding='utf-8'\n",
        "        html=etree.HTML(resp.text)\n",
        "        #每个版块\n",
        "        h_list=html.xpath('//div[@class=\"list\"]/div/h4')\n",
        "        d_list=html.xpath('//div[@class=\"list\"]/div/div')\n",
        "        for h ,d in zip(h_list,d_list):\n",
        "            node_name=''.join(h.xpath('.//a/text()'))\n",
        "            #print(node_name)\n",
        "            li_list=d.xpath('./ul/li')\n",
        "            for li in li_list:\n",
        "                title=''.join(li.xpath('.//a/text()'))\n",
        "                link=f'http://www.macaodaily.com/html/{date}/'+''.join(li.xpath('.//a/@href'))\n",
        "                print(date,node_name,title,link)\n",
        "                r=get_content(date, node_name, title, link)\n",
        "                result.append(r)\n",
        "    news_df=pd.DataFrame(result)\n",
        "    news_df.columns=['date', 'node_name', 'title', 'link','content']\n",
        "    print(news_df)\n",
        "    return news_df\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start =\"2020/10/01\"\n",
        "end = \"2020/10/02\"\n",
        "news_df=news(start, end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#news_df.to_excel(f\"{start}至{end}\".replace('/','')+'.xlsx',index=False)\n",
        "#news_df.to_excel(\"test.xlsx\",index=False)\n",
        "news_df.to_pickle('./news_df-oneday.pkl')\n",
        "#news_df = pd.read_csv('./news_df.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7jDx2D1ZLi6"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "#stopwords_list = stopwords.words('english')\n",
        "from nltk.corpus import names, stopwords, words\n",
        "stopwords_list = stopwords.words('chinese')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string\n",
        "# Take a string as input and perform the corresponding cleaning\n",
        "def clean(doc): \n",
        "    # Clean up html tags\n",
        "    doc = doc.replace(\"</br>\", \" \")\n",
        "    # remove punctuation and numbers\n",
        "    doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
        "    # remove stopwords\n",
        "    doc = \" \".join([token for token in doc.split() if token not in stopwords_list]) \n",
        "    return doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "news_df['news_type'] = news_df['node_name'].apply(lambda x: x.split('：')[1])\n",
        "news_df['content'] = news_df['content'].apply(lambda x: x.replace(u'\\xa0', u' '))\n",
        "news_df['content'] = news_df['content'].apply(clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "a=news_df['news_type'].unique()\n",
        "news_df['news_type_num'] = labelencoder.fit_transform(news_df['news_type'])\n",
        "b=news_df['news_type_num'].unique()\n",
        "label=news_df['news_type_num'].value_counts().shape[0]\n",
        "\n",
        "nodenum=[]\n",
        "for i,j in zip(a,b):\n",
        "  nodenum.append([i,j])\n",
        "nodenum"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "news_df['news_type_num'][0]\n",
        "news_df['content'][0]\n",
        "int_label=news_df['news_type_num'].value_counts().shape[0]\n",
        "int_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "condition1 = news_df['news_type']=='澳聞'\n",
        "macau_news = news_df[condition1]\n",
        "macau_news_content = macau_news['content']\n",
        "a=macau_news_content.apply(lambda x: x.split('【')[0])\n",
        "b=macau_news_content.apply(lambda x: x.split('【')[1:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "macau_news_content"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
